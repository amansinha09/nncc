{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers==4.1.1 &> /dev/null\nimport importlib\nimport sys\nimportlib.reload(sys.modules['pkg_resources'])\n\nsys.modules['pkg_resources'].get_distribution('tokenizers').version\n\nimport transformers\ntransformers.__version__","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:09:19.666059Z","iopub.execute_input":"2022-04-05T06:09:19.666588Z","iopub.status.idle":"2022-04-05T06:09:45.567463Z","shell.execute_reply.started":"2022-04-05T06:09:19.666548Z","shell.execute_reply":"2022-04-05T06:09:45.566764Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install mendelai-brat-parser &> /dev/null\nfrom brat_parser import get_entities_relations_attributes_groups\n\nimport torch \nimport spacy\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#!pip uninstall nltk &> /dev/null\n#!pip install -U nltk &> /dev/null\nimport nltk\nfrom nltk.tokenize import sent_tokenize,word_tokenize\nnltk.download('punkt')\n\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom tqdm import tqdm, trange\n\nMAX_LEN = 75\nbatch_size = 32","metadata":{"id":"47osPwG1dVdu","outputId":"329884e3-d3f3-4351-af2b-3636634e3318","execution":{"iopub.status.busy":"2022-04-05T06:09:45.569200Z","iopub.execute_input":"2022-04-05T06:09:45.569611Z","iopub.status.idle":"2022-04-05T06:09:59.653323Z","shell.execute_reply.started":"2022-04-05T06:09:45.569573Z","shell.execute_reply":"2022-04-05T06:09:59.652252Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"rc3t0n5bFeUy","outputId":"2dcefa15-c202-45a1-8b9b-dc4774f8d869"}},{"cell_type":"markdown","source":"# Task 1: NER","metadata":{"id":"5DvsWN77oJ4z"}},{"cell_type":"markdown","source":"## Data Extraction","metadata":{"id":"RNvSjGo-oLO8"}},{"cell_type":"markdown","source":"train = pd.DataFrame(columns = [\"Id\",\"Doc_Id\",\"Sent_Id\",\"Word\",\"Tag\"])\n\nsent_id = 0\nid = 0\ndoc_id = 0\nfor path in glob(\"/content/drive/MyDrive/CMED/Data/trainingdata_v3/train/*\"):\n  \n  if path.endswith(\".ann\"):\n    continue\n\n  doc_id += 1\n  if doc_id % 25 == 0:\n    print(doc_id,end = ' ')\n\n  span = 0\n  with open(path) as txt:\n    raw = txt.read()\n\n  entities,_,_,_ = get_entities_relations_attributes_groups(path.replace(\".txt\",\".ann\"))\n  entl = []\n  for i in entities:\n    if (entities[i].span.__len__())>1:\n      entities[i].span = ((entities[i].span[0][0],entities[i].span[-1][-1]),)\n    entl.append([*entities[i].span[0],entities[i].text,entities[i].type])\n  entl = sorted(entl)[::-1]\n\n  for sent in sent_tokenize(raw):\n    sent_id += 1\n    for word in word_tokenize(sent):\n      id += 1\n      train = train.append(pd.DataFrame(data = np.array([[id,doc_id,sent_id,word,np.nan]]),columns = [\"Id\",\"Doc_Id\",\"Sent_Id\",\"Word\",\"Tag\"]))\n      span += raw[span:].find(word)\n      while True:\n        if len(entl)>0 and entl[-1][0] <= span:\n          if entl[-1][1] <= span:\n            entl.pop()\n          else:\n            if span == entl[-1][0]:\n              train.iloc[-1,-1] = \"B-\" + entl[-1][3]\n            else:\n              train.iloc[-1,-1] = \"I-\" + entl[-1][3]\n            break\n        else:\n          train.iloc[-1,-1] = 'O'\n          break","metadata":{"id":"PP6GnelOnkez","outputId":"fde82513-a198-4177-bb03-537894cb39ba"}},{"cell_type":"markdown","source":"train.to_csv(\"TRAIN_CMED_NER_BIO2.csv\")","metadata":{"id":"bmb6yrdAMf4Y"}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{"id":"j1Kwotaei6k2"}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/topsecret/TRAIN_CMED_NER_BIO2.csv\")\ntrain_ner = train.copy()\ntrain_ner = train_ner.drop(np.where(train_ner[\"Word\"].isnull())[0],axis=0)\ntrain_ner[\"Tag\"] = [word[0] for word in train_ner[\"Tag\"]]\ntrain_ner = train_ner.set_index(\"Id\")\ntrain_ner = train_ner.drop(\"Unnamed: 0\",axis = 1)\ndel train\ntrain_ner.head()","metadata":{"id":"4oEOyyInjNWB","outputId":"abde2742-53c3-4c6d-b54f-8fddfe8c9ab0","execution":{"iopub.status.busy":"2022-04-05T06:09:59.657568Z","iopub.execute_input":"2022-04-05T06:09:59.659601Z","iopub.status.idle":"2022-04-05T06:10:00.142431Z","shell.execute_reply.started":"2022-04-05T06:09:59.659561Z","shell.execute_reply":"2022-04-05T06:10:00.141774Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"grp_obj = train_ner.groupby(\"Sent_Id\").apply(lambda x:[(word,label) for word,label in zip(x[\"Word\"],x[\"Tag\"])])\n\nsentences = [[tpl[0] for tpl in sent] for sent in grp_obj]\nlabels = [[tpl[1] for tpl in sent] for sent in grp_obj]\n\nsaved_sentences = sentences\nsaved_labels = labels\n \ntag_values = list(set(train_ner[\"Tag\"].values))\ntag_values.append(\"PAD\")\ntag2idx = {t: i for i, t in enumerate(tag_values)}","metadata":{"id":"1z37K8dNFABy","execution":{"iopub.status.busy":"2022-04-05T06:10:00.146906Z","iopub.execute_input":"2022-04-05T06:10:00.148052Z","iopub.status.idle":"2022-04-05T06:10:01.555212Z","shell.execute_reply.started":"2022-04-05T06:10:00.148014Z","shell.execute_reply":"2022-04-05T06:10:01.554420Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False) \n\ndef get_tokenized_sentences_and_labels():\n\n  global sentences,labels\n  sent = []\n  lab = []\n\n  for i,j in zip(sentences,labels):\n    sent.append([])\n    lab.append([])\n    for ind in range(len(i)):\n      temp = tokenizer.tokenize(i[ind])\n      sent[-1].extend(temp)\n      lab[-1].extend((j[ind]*len(temp)))\n  return sent,lab\n  \nsentences,labels = get_tokenized_sentences_and_labels()","metadata":{"id":"8qULi2lSFAFK","outputId":"347d1480-f092-405c-e356-4b8b5217856a","execution":{"iopub.status.busy":"2022-04-05T06:10:01.556481Z","iopub.execute_input":"2022-04-05T06:10:01.556758Z","iopub.status.idle":"2022-04-05T06:10:16.987091Z","shell.execute_reply.started":"2022-04-05T06:10:01.556723Z","shell.execute_reply":"2022-04-05T06:10:16.986262Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def normalize_longer_sequences():\n  global sentences,labels\n\n  inds = []\n\n  for i in range(len(sentences)):\n    if len(sentences[i]) > MAX_LEN:\n      inds.append(i)\n\n  temp_sent = np.array(sentences,dtype = object)[inds]\n  temp_lab = np.array(labels,dtype = object)[inds]\n\n  sentences = np.delete(np.array(sentences,dtype = object),inds,0)\n  labels = np.delete(np.array(labels,dtype = object),inds,0)\n\n  save_sent = []\n  save_lab = []\n  for i in range(len(temp_sent)):\n    for k in range(len(temp_sent[i])//(MAX_LEN//2)-1):\n      save_sent.append(temp_sent[i][k*(MAX_LEN//2):k*(MAX_LEN//2)+75])\n      save_lab.append(temp_lab[i][k*(MAX_LEN//2):k*(MAX_LEN//2)+75])\n\n  sentences = np.concatenate([sentences,save_sent],axis = 0)\n  labels = np.concatenate([labels,save_lab],axis = 0)\n\nnormalize_longer_sequences()\n\nfor i,j in zip(sentences,labels):\n  assert(len(i) == len(j))","metadata":{"id":"CYukUocmN_xA","outputId":"78e4e8a8-3185-450c-d60d-35896bd046bf","execution":{"iopub.status.busy":"2022-04-05T06:10:16.990402Z","iopub.execute_input":"2022-04-05T06:10:16.990630Z","iopub.status.idle":"2022-04-05T06:10:17.068855Z","shell.execute_reply.started":"2022-04-05T06:10:16.990602Z","shell.execute_reply":"2022-04-05T06:10:17.068018Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in sentences],\n                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n                          truncating=\"post\", padding=\"post\")\n\ntags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n                     dtype=\"long\", truncating=\"post\")\n\nattention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]","metadata":{"id":"vHyM-2LYAmZU","execution":{"iopub.status.busy":"2022-04-05T06:10:17.070506Z","iopub.execute_input":"2022-04-05T06:10:17.071096Z","iopub.status.idle":"2022-04-05T06:10:21.648212Z","shell.execute_reply.started":"2022-04-05T06:10:17.071053Z","shell.execute_reply":"2022-04-05T06:10:21.647437Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks = train_test_split(input_ids, tags, attention_masks, random_state= 0, test_size=0.15)\n\ntr_inputs = torch.tensor(tr_inputs)\nval_inputs = torch.tensor(val_inputs)\ntr_tags = torch.tensor(tr_tags)\nval_tags = torch.tensor(val_tags)\ntr_masks = torch.tensor(tr_masks)\nval_masks = torch.tensor(val_masks)","metadata":{"id":"iwcwwoSu4KQJ","execution":{"iopub.status.busy":"2022-04-05T06:10:21.649722Z","iopub.execute_input":"2022-04-05T06:10:21.649996Z","iopub.status.idle":"2022-04-05T06:10:21.835941Z","shell.execute_reply.started":"2022-04-05T06:10:21.649952Z","shell.execute_reply":"2022-04-05T06:10:21.835186Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nvalid_data = TensorDataset(val_inputs, val_masks, val_tags)\nvalid_sampler = SequentialSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)","metadata":{"id":"01FXEiVFH5em","execution":{"iopub.status.busy":"2022-04-05T06:10:21.837245Z","iopub.execute_input":"2022-04-05T06:10:21.837476Z","iopub.status.idle":"2022-04-05T06:10:21.842160Z","shell.execute_reply.started":"2022-04-05T06:10:21.837444Z","shell.execute_reply":"2022-04-05T06:10:21.841469Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{"id":"1jZJ-KBFI6jN"}},{"cell_type":"markdown","source":"### BERT","metadata":{"id":"8pfq2VyGKuY1"}},{"cell_type":"markdown","source":"#### Utility procedures for training BERT","metadata":{"id":"p0Dx4Wm5L0Pu"}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=2).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n\ndef plot_confusion_matrix(cnf_matrix,title = None):\n    plt.figure(figsize = (3.3,3.3))\n    sns.heatmap(cnf_matrix,annot = True,cbar = False)\n    plt.xticks([0.5,1.5,2.5,3.5])\n    plt.yticks([0.5,1.5,2.5,3.5])\n    plt.xlabel(\"Predicted Class\")\n    plt.ylabel(\"True Class\")\n    plt.gca().set_xticklabels([tag_values[w] for w in range(4)])\n    plt.gca().set_yticklabels([tag_values[w] for w in range(4)])\n    plt.gca().xaxis.set_ticks_position(\"top\")\n    plt.gca().xaxis.set_label_position(\"top\")\n    if title:\n        plt.title(title)","metadata":{"id":"8heNCefRLKKv","execution":{"iopub.status.busy":"2022-04-05T06:10:21.845951Z","iopub.execute_input":"2022-04-05T06:10:21.846410Z","iopub.status.idle":"2022-04-05T06:10:21.857652Z","shell.execute_reply.started":"2022-04-05T06:10:21.846369Z","shell.execute_reply":"2022-04-05T06:10:21.856813Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Token_Classifier_With_Pretrained_Bert_Base(torch.nn.Module):\n  def __init__(self,base,classes = 4):\n    super().__init__()\n    self.n_classes = classes\n    self.base = base\n    self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n    self.classifier = torch.nn.Linear(in_features=768, out_features=classes, bias=True)\n    self.criterion = torch.nn.CrossEntropyLoss()\n\n  def forward(self,bert_input,attention_mask,token_type_ids = None,labels = None):\n    out = self.base(bert_input,attention_mask = attention_mask,token_type_ids = None)[0]\n    out = self.dropout(out)\n    out = self.classifier(out)\n    if labels is None:\n      return out\n    else:\n      return (self.criterion(out.reshape(-1,4),labels.reshape(-1)),out)","metadata":{"id":"fk4jrDBoOwzW","execution":{"iopub.status.busy":"2022-04-05T06:10:21.858937Z","iopub.execute_input":"2022-04-05T06:10:21.859158Z","iopub.status.idle":"2022-04-05T06:10:21.873256Z","shell.execute_reply.started":"2022-04-05T06:10:21.859132Z","shell.execute_reply":"2022-04-05T06:10:21.872392Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def finetune_procedure_bert_for_ner(model,epochs,dataloader_train,dataloader_valid,optimizer,criterion = None,scheduler = None,max_grad_norm = 1.0,early_stopping = False,patience = 5,stopping_criteria = None,PATH = None):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    if torch.cuda.is_available():\n      model.cuda()\n    if early_stopping:\n      assert(stopping_criteria is not None)\n      assert(PATH is not None)\n      curp = 0\n      best_score = 0\n\n    history = {\n        \"average_train_loss_per_batch\" : [],\n        \"average_valid_loss_per_batch\" : [],\n        \"train_confusion_matrix\" : None,\n        \"valid_confusion_matrix\" : None,\n    }\n    \n    for i in range(1,1+epochs):\n        print(\"Epoch number {}:\".format(i))\n        \n        # ========================================\n        #              Training\n        # ========================================\n        model.train()\n        iterator_dataloader_train = iter(dataloader_train)\n        train_loss = 0\n        cnf_matrix = np.zeros((4,4))\n        \n        for _ in trange(len(dataloader_train)):\n            \n            batch = next(iterator_dataloader_train)\n            train_input,train_mask,train_label = (i.to(device) for i in batch)\n            \n            model.zero_grad()\n            \n            outputs = model(train_input, token_type_ids=None, attention_mask=train_mask, labels=train_label)\n            \n            if criterion is not None:\n                loss = criterion(outputs[1].reshape(-1,4),train_label.reshape(-1))\n            else:\n                loss = outputs[0]\n            \n            loss.backward()\n            train_loss += loss.item()\n            \n            torch.nn.utils.clip_grad_norm_(parameters = model.parameters(),max_norm = max_grad_norm)\n            \n            optimizer.step()\n            if scheduler is not None:\n                scheduler.step()\n                \n            x = confusion_matrix(train_label.detach().to(\"cpu\").numpy().ravel(),outputs[1].detach().to(\"cpu\").numpy().argmax(axis = -1).ravel())\n            cnf_matrix += np.pad(x,[0,4 - x.shape[0]])\n            \n        history[\"average_train_loss_per_batch\"].append( train_loss / len(dataloader_train) )\n        print(\"Average_Train_Loss_per_Batch:\",history[\"average_train_loss_per_batch\"][-1])\n        plot_confusion_matrix(cnf_matrix,\"Training_Epoch_{}\".format(i))\n        save_train_cnf_matrix = cnf_matrix\n          \n        # ========================================\n        #              Validation\n        # ========================================\n        model.eval()\n        iterator_dataloader_valid = iter(dataloader_valid)\n        valid_loss = 0\n        valid_accuracy = 0\n        cnf_matrix = np.zeros((4,4))\n        \n        for _ in trange(len(dataloader_valid)):\n            batch = next(iterator_dataloader_valid)\n            valid_input,valid_mask,valid_label = (i.to(device) for i in batch)\n            \n            with torch.no_grad():\n                outputs = model(valid_input, token_type_ids=None,\n                                attention_mask=valid_mask, labels=valid_label)\n            \n            logits = outputs[1].detach().cpu().numpy()\n            label_ids = valid_label.to('cpu').numpy()\n            \n            if criterion is not None:\n                valid_loss += criterion(outputs[1].reshape(-1,4),valid_label.reshape(-1)).item()\n            else:\n                valid_loss += outputs[0].item()\n            \n            valid_accuracy += flat_accuracy(logits, label_ids)\n            x = confusion_matrix(valid_label.detach().to(\"cpu\").numpy().ravel(),outputs[1].detach().to(\"cpu\").numpy().argmax(axis = -1).ravel())\n            cnf_matrix += np.pad(x,[0,4 - x.shape[0]])\n            \n\n        history[\"average_valid_loss_per_batch\"].append( valid_loss / len(dataloader_valid) )\n        print(\"Average_Valid_Loss_per_Batch: \",history[\"average_valid_loss_per_batch\"][-1])\n        print(\"Validation Accuracy: {}\".format(valid_accuracy/len(dataloader_valid)))\n        plot_confusion_matrix(cnf_matrix,\"Validation_Epoch_{}\".format(i))\n\n        if early_stopping:\n          current_score = stopping_criteria(cnf_matrix)\n          if best_score < current_score:\n            torch.save(model.state_dict(), PATH)\n            best_score = current_score\n            curp = 0\n            history[\"valid_confusion_matrix\"] = cnf_matrix\n            history[\"train_confusion_matrix\"] = save_train_cnf_matrix\n          else:\n            curp += 1\n            if curp > patience:\n              break\n          print(\"Micro Average F1 score : {} , Current_steps_with_decreasing_score : {}\".format(current_score,curp))\n        else :\n            history[\"valid_confusion_matrix\"] = cnf_matrix\n            history[\"train_confusion_matrix\"] = save_train_cnf_matrix\n\n    return history","metadata":{"id":"YYoH-MeCLRIt","execution":{"iopub.status.busy":"2022-04-05T06:10:21.874962Z","iopub.execute_input":"2022-04-05T06:10:21.875260Z","iopub.status.idle":"2022-04-05T06:10:21.903774Z","shell.execute_reply.started":"2022-04-05T06:10:21.875221Z","shell.execute_reply":"2022-04-05T06:10:21.902963Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def print_training_results(history):\n    func = lambda x: x.diagonal() / x.sum(axis = 1)\n    fig,ax = plt.subplots(1,2,figsize = (12,3))\n    ax[0].plot(history[\"average_train_loss_per_batch\"])\n    ax[1].plot(history[\"average_valid_loss_per_batch\"])\n    ax[0].set_title(\"average_train_loss_per_batch\")\n    ax[1].set_title(\"average_valid_loss_per_batch\")\n\n    df = pd.DataFrame(np.array([func(history[\"train_confusion_matrix\"]),func(history[\"train_confusion_matrix\"].T)]).T,index = tag_values,columns = [\"Precision\",\"Recall\"])\n    df[\"F1-score\"] = ( 2 * df[\"Precision\"] * df[\"Recall\"] ) / (df[\"Precision\"] + df[\"Recall\"])\n    print(\"Metrics on training data after training:\")\n    print(df)\n    print()\n    df = pd.DataFrame(np.array([func(history[\"valid_confusion_matrix\"]),func(history[\"valid_confusion_matrix\"].T)]).T,index = tag_values,columns = [\"Precision\",\"Recall\"])\n    df[\"F1-score\"] = ( 2 * df[\"Precision\"] * df[\"Recall\"] ) / (df[\"Precision\"] + df[\"Recall\"])\n    print(\"Metrics on validation results after training:\")\n    print(df)","metadata":{"id":"d3wADWztcizZ","execution":{"iopub.status.busy":"2022-04-05T06:10:21.905380Z","iopub.execute_input":"2022-04-05T06:10:21.905698Z","iopub.status.idle":"2022-04-05T06:10:21.917369Z","shell.execute_reply.started":"2022-04-05T06:10:21.905661Z","shell.execute_reply":"2022-04-05T06:10:21.916388Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#### Training Bert Models","metadata":{"id":"u0kts3OELItj"}},{"cell_type":"markdown","source":"##### bert-base-cased","metadata":{"id":"JkVn0KUyMeXs"}},{"cell_type":"code","source":"import transformers\nfrom transformers import BertForTokenClassification, AdamW\nfrom transformers import get_linear_schedule_with_warmup","metadata":{"id":"VTM5I8OlIp9D","execution":{"iopub.status.busy":"2022-04-05T06:10:21.918910Z","iopub.execute_input":"2022-04-05T06:10:21.919708Z","iopub.status.idle":"2022-04-05T06:10:21.928794Z","shell.execute_reply.started":"2022-04-05T06:10:21.919664Z","shell.execute_reply":"2022-04-05T06:10:21.927966Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained(\n    \"bert-base-cased\",\n    num_labels=len(tag2idx),\n    output_attentions = False,\n    output_hidden_states = False\n)","metadata":{"id":"nAVL1KQqKxmy","execution":{"iopub.status.busy":"2022-04-05T06:10:21.930384Z","iopub.execute_input":"2022-04-05T06:10:21.930742Z","iopub.status.idle":"2022-04-05T06:10:36.192528Z","shell.execute_reply.started":"2022-04-05T06:10:21.930700Z","shell.execute_reply":"2022-04-05T06:10:36.191602Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"FULL_FINETUNING = True\nif FULL_FINETUNING:\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.0}\n    ]\nelse:\n    param_optimizer = list(model.classifier.named_parameters())\n    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n\noptimizer = AdamW(\n    optimizer_grouped_parameters,\n    lr=3e-5,\n    eps=1e-8\n)","metadata":{"id":"OHr-24tOK3Gc","execution":{"iopub.status.busy":"2022-04-05T06:10:36.194233Z","iopub.execute_input":"2022-04-05T06:10:36.194518Z","iopub.status.idle":"2022-04-05T06:10:36.204207Z","shell.execute_reply.started":"2022-04-05T06:10:36.194471Z","shell.execute_reply":"2022-04-05T06:10:36.203288Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nmax_grad_norm = 1.0\n\n#############################################\n\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)","metadata":{"id":"XNa1ERRoK_Tl","execution":{"iopub.status.busy":"2022-04-05T06:10:36.205576Z","iopub.execute_input":"2022-04-05T06:10:36.206423Z","iopub.status.idle":"2022-04-05T06:10:36.217767Z","shell.execute_reply.started":"2022-04-05T06:10:36.206380Z","shell.execute_reply":"2022-04-05T06:10:36.216657Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class_weight = [np.sum(np.array([np.sum(np.array(j) == tag2idx[w]) for j in tags])) for w in tag_values]\nclass_weight = 1 / np.array(class_weight,dtype = np.float32)\nclass_weight = np.array(class_weight) / np.array(class_weight).sum()\n\ncriterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weight).to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))","metadata":{"id":"3hyE30ZGtYmi","execution":{"iopub.status.busy":"2022-04-05T06:10:36.220989Z","iopub.execute_input":"2022-04-05T06:10:36.221717Z","iopub.status.idle":"2022-04-05T06:10:44.850621Z","shell.execute_reply.started":"2022-04-05T06:10:36.221673Z","shell.execute_reply":"2022-04-05T06:10:44.849859Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"try :\n    os.mkdir(\"BERT_BASE_CASED\")\nexcept:\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:10:44.852022Z","iopub.execute_input":"2022-04-05T06:10:44.852315Z","iopub.status.idle":"2022-04-05T06:10:44.856862Z","shell.execute_reply.started":"2022-04-05T06:10:44.852280Z","shell.execute_reply":"2022-04-05T06:10:44.856086Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def es_criteria(cnf_matrix):\n  precision = cnf_matrix.diagonal() / np.sum(cnf_matrix,axis = 0)\n  recall = cnf_matrix.diagonal() / np.sum(cnf_matrix,axis = 1)\n  f1 = (2 * precision * recall) / (precision + recall)\n  return f1.mean()\n\n#history = finetune_procedure_bert_for_ner(model,epochs,train_dataloader,valid_dataloader,optimizer,criterion,scheduler,max_grad_norm,early_stopping = True,patience = 15,stopping_criteria = es_criteria,PATH = \"BERT_BASE_CASED/state_dict\")","metadata":{"id":"o8Wv5mq9NlX4","outputId":"5b12b0a0-725d-4288-9c95-95ea31a216de","execution":{"iopub.status.busy":"2022-04-05T06:10:44.858336Z","iopub.execute_input":"2022-04-05T06:10:44.858809Z","iopub.status.idle":"2022-04-05T06:10:44.867436Z","shell.execute_reply.started":"2022-04-05T06:10:44.858771Z","shell.execute_reply":"2022-04-05T06:10:44.866623Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#print_training_results(history)","metadata":{"id":"C2Hv5rA7V_Uv","execution":{"iopub.status.busy":"2022-04-05T06:10:44.869033Z","iopub.execute_input":"2022-04-05T06:10:44.869319Z","iopub.status.idle":"2022-04-05T06:10:44.876974Z","shell.execute_reply.started":"2022-04-05T06:10:44.869280Z","shell.execute_reply":"2022-04-05T06:10:44.875968Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"##### Bio-Clinical Bert","metadata":{"id":"r_08AackRKT0"}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\nbase_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\nmodel = Token_Classifier_With_Pretrained_Bert_Base(base_model,4)","metadata":{"id":"L9eEtE48RdZi","execution":{"iopub.status.busy":"2022-04-05T06:10:44.878547Z","iopub.execute_input":"2022-04-05T06:10:44.879083Z","iopub.status.idle":"2022-04-05T06:11:00.883725Z","shell.execute_reply.started":"2022-04-05T06:10:44.879045Z","shell.execute_reply":"2022-04-05T06:11:00.882974Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"sentences = saved_sentences\nlabels = saved_labels\n\nsentences,labels = get_tokenized_sentences_and_labels()\nnormalize_longer_sequences()\n\nfor i,j in zip(sentences,labels):\n  assert(len(i) == len(j))\n\ninput_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in sentences],\n                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n                          truncating=\"post\", padding=\"post\")\n\ntags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n                     dtype=\"long\", truncating=\"post\")\n\nattention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]\n\ntr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks = train_test_split(input_ids, tags, attention_masks, random_state= 0, test_size=0.15)\n\ntr_inputs = torch.tensor(tr_inputs)\nval_inputs = torch.tensor(val_inputs)\ntr_tags = torch.tensor(tr_tags)\nval_tags = torch.tensor(val_tags)\ntr_masks = torch.tensor(tr_masks)\nval_masks = torch.tensor(val_masks)\n\ntrain_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nvalid_data = TensorDataset(val_inputs, val_masks, val_tags)\nvalid_sampler = SequentialSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)","metadata":{"id":"PFzrxOvzT9Gh","outputId":"9a16ff37-7035-43d3-ec1a-d661b65dfad7","execution":{"iopub.status.busy":"2022-04-05T06:11:00.885267Z","iopub.execute_input":"2022-04-05T06:11:00.885770Z","iopub.status.idle":"2022-04-05T06:11:20.633167Z","shell.execute_reply.started":"2022-04-05T06:11:00.885730Z","shell.execute_reply":"2022-04-05T06:11:20.632333Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"FULL_FINETUNING = True\nif FULL_FINETUNING:\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.0}\n    ]\nelse:\n    param_optimizer = list(model.classifier.named_parameters())\n    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n\noptimizer = AdamW(\n    optimizer_grouped_parameters,\n    lr=3e-5,\n    eps=1e-8\n)","metadata":{"id":"0alU6mqcVrTu","execution":{"iopub.status.busy":"2022-04-05T06:11:20.634668Z","iopub.execute_input":"2022-04-05T06:11:20.634913Z","iopub.status.idle":"2022-04-05T06:11:20.643469Z","shell.execute_reply.started":"2022-04-05T06:11:20.634879Z","shell.execute_reply":"2022-04-05T06:11:20.642757Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nmax_grad_norm = 1.0\n\n#############################################\n\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)","metadata":{"id":"mhqfbg5YjLT1","execution":{"iopub.status.busy":"2022-04-05T06:11:20.645122Z","iopub.execute_input":"2022-04-05T06:11:20.645671Z","iopub.status.idle":"2022-04-05T06:11:20.672809Z","shell.execute_reply.started":"2022-04-05T06:11:20.645629Z","shell.execute_reply":"2022-04-05T06:11:20.672047Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class_weight = [np.sum(np.array([np.sum(np.array(j) == tag2idx[w]) for j in tags])) for w in tag_values]\nclass_weight = 1 / np.array(class_weight,dtype = np.float32)\nclass_weight = np.array(class_weight) / np.array(class_weight).sum()\n\ncriterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weight).to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))","metadata":{"id":"Y46CK1gqja1J","execution":{"iopub.status.busy":"2022-04-05T06:11:20.675285Z","iopub.execute_input":"2022-04-05T06:11:20.675556Z","iopub.status.idle":"2022-04-05T06:11:21.299175Z","shell.execute_reply.started":"2022-04-05T06:11:20.675523Z","shell.execute_reply":"2022-04-05T06:11:21.298369Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"try :\n    os.mkdir(\"BIO_CLINICAL_BERT\")\nexcept:\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:21.300373Z","iopub.execute_input":"2022-04-05T06:11:21.302283Z","iopub.status.idle":"2022-04-05T06:11:21.306439Z","shell.execute_reply.started":"2022-04-05T06:11:21.302241Z","shell.execute_reply":"2022-04-05T06:11:21.305377Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def es_criteria(cnf_matrix):\n  precision = cnf_matrix.diagonal() / np.sum(cnf_matrix,axis = 0)\n  recall = cnf_matrix.diagonal() / np.sum(cnf_matrix,axis = 1)\n  f1 = (2 * precision * recall) / (precision + recall)\n  return f1.mean()\n\n#history = finetune_procedure_bert_for_ner(model,epochs,train_dataloader,valid_dataloader,optimizer,criterion,scheduler,max_grad_norm,early_stopping = True,patience = 15,stopping_criteria = es_criteria,PATH = \"BIO_CLINICAL_BERT/state_dict\")","metadata":{"id":"Avel3avTjtN_","execution":{"iopub.status.busy":"2022-04-05T06:11:21.311503Z","iopub.execute_input":"2022-04-05T06:11:21.312087Z","iopub.status.idle":"2022-04-05T06:11:21.318541Z","shell.execute_reply.started":"2022-04-05T06:11:21.312046Z","shell.execute_reply":"2022-04-05T06:11:21.317504Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#print_training_results(history)","metadata":{"id":"NMI94-GijthU","execution":{"iopub.status.busy":"2022-04-05T06:11:21.320217Z","iopub.execute_input":"2022-04-05T06:11:21.320764Z","iopub.status.idle":"2022-04-05T06:11:21.328053Z","shell.execute_reply.started":"2022-04-05T06:11:21.320723Z","shell.execute_reply":"2022-04-05T06:11:21.327220Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"#### BioELECTRA","metadata":{}},{"cell_type":"code","source":"class Token_Classifier_From_BioElectra(torch.nn.Module):\n  def __init__(self,base,classes = 4):\n    super().__init__()\n    self.n_classes = classes\n    self.base = base.electra\n    self.intermediate = base.discriminator_predictions.dense\n    self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n    self.classifier = torch.nn.Linear(in_features=768, out_features=classes, bias=True)\n    self.criterion = torch.nn.CrossEntropyLoss()\n\n  def forward(self,bert_input,attention_mask,token_type_ids = None,labels = None):\n    out = self.base(bert_input,attention_mask = attention_mask,token_type_ids = None).__getitem__(0)\n    out = self.intermediate(out)\n    out = self.dropout(out)\n    out = self.classifier(out)\n    if labels is None:\n      return out\n    else:\n      return (self.criterion(out.reshape(-1,4),labels.reshape(-1)),out)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:21.329230Z","iopub.execute_input":"2022-04-05T06:11:21.330070Z","iopub.status.idle":"2022-04-05T06:11:21.341477Z","shell.execute_reply.started":"2022-04-05T06:11:21.330032Z","shell.execute_reply":"2022-04-05T06:11:21.340629Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from transformers import ElectraForPreTraining, ElectraTokenizerFast\n\nbase_model = ElectraForPreTraining.from_pretrained(\"kamalkraj/bioelectra-base-discriminator-pubmed\")\ntokenizer = ElectraTokenizerFast.from_pretrained(\"kamalkraj/bioelectra-base-discriminator-pubmed\")\nmodel = Token_Classifier_From_BioElectra(base_model,4)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:21.343693Z","iopub.execute_input":"2022-04-05T06:11:21.344282Z","iopub.status.idle":"2022-04-05T06:11:38.215308Z","shell.execute_reply.started":"2022-04-05T06:11:21.344238Z","shell.execute_reply":"2022-04-05T06:11:38.214549Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"sentences = saved_sentences\nlabels = saved_labels\n\nsentences,labels = get_tokenized_sentences_and_labels()\nnormalize_longer_sequences()\n\nfor i,j in zip(sentences,labels):\n  assert(len(i) == len(j))\n\ninput_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in sentences],\n                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n                          truncating=\"post\", padding=\"post\")\n\ntags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n                     dtype=\"long\", truncating=\"post\")\n\nattention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]\n\ntr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks = train_test_split(input_ids, tags, attention_masks, random_state= 0, test_size=0.15)\n\ntr_inputs = torch.tensor(tr_inputs)\nval_inputs = torch.tensor(val_inputs)\ntr_tags = torch.tensor(tr_tags)\nval_tags = torch.tensor(val_tags)\ntr_masks = torch.tensor(tr_masks)\nval_masks = torch.tensor(val_masks)\n\ntrain_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nvalid_data = TensorDataset(val_inputs, val_masks, val_tags)\nvalid_sampler = SequentialSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:38.216439Z","iopub.execute_input":"2022-04-05T06:11:38.216693Z","iopub.status.idle":"2022-04-05T06:11:56.430675Z","shell.execute_reply.started":"2022-04-05T06:11:38.216661Z","shell.execute_reply":"2022-04-05T06:11:56.429954Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"FULL_FINETUNING = True\n\n###################################333\nif FULL_FINETUNING:\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.0}\n    ]\nelse:\n    param_optimizer = list(model.classifier.named_parameters())\n    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n\noptimizer = AdamW(\n    optimizer_grouped_parameters,\n    lr=3e-5,\n    eps=1e-8\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:56.432124Z","iopub.execute_input":"2022-04-05T06:11:56.432374Z","iopub.status.idle":"2022-04-05T06:11:56.441428Z","shell.execute_reply.started":"2022-04-05T06:11:56.432340Z","shell.execute_reply":"2022-04-05T06:11:56.440757Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"epochs = 100\nmax_grad_norm = 1.0\n\n#############################################\n\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:56.443067Z","iopub.execute_input":"2022-04-05T06:11:56.443608Z","iopub.status.idle":"2022-04-05T06:11:56.459006Z","shell.execute_reply.started":"2022-04-05T06:11:56.443569Z","shell.execute_reply":"2022-04-05T06:11:56.458100Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class_weight = [np.sum(np.array([np.sum(np.array(j) == tag2idx[w]) for j in tags])) for w in tag_values]\nclass_weight = 1 / np.array(class_weight,dtype = np.float32)\nclass_weight = np.array(class_weight) / np.array(class_weight).sum()\n\ncriterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weight).to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:56.461280Z","iopub.execute_input":"2022-04-05T06:11:56.461739Z","iopub.status.idle":"2022-04-05T06:11:57.036219Z","shell.execute_reply.started":"2022-04-05T06:11:56.461670Z","shell.execute_reply":"2022-04-05T06:11:57.035258Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"try :\n    os.mkdir(\"BIO_ELECTRA\")\nexcept:\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:57.037603Z","iopub.execute_input":"2022-04-05T06:11:57.037879Z","iopub.status.idle":"2022-04-05T06:11:57.042539Z","shell.execute_reply.started":"2022-04-05T06:11:57.037842Z","shell.execute_reply":"2022-04-05T06:11:57.041701Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def es_criteria(cnf_matrix):\n  precision = cnf_matrix.diagonal() / np.sum(cnf_matrix,axis = 0)\n  recall = cnf_matrix.diagonal() / np.sum(cnf_matrix,axis = 1)\n  f1 = (2 * precision * recall) / (precision + recall)\n  return f1.mean()\n\nhistory = finetune_procedure_bert_for_ner(model,epochs,train_dataloader,valid_dataloader,optimizer,criterion,scheduler,max_grad_norm,early_stopping = True,patience = 2000,stopping_criteria = es_criteria,PATH = \"BIO_ELECTRA/state_dict\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T06:11:57.044071Z","iopub.execute_input":"2022-04-05T06:11:57.044335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_training_results(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}